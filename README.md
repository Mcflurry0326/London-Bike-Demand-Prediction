# London Bike Demand Prediction
# London Bike Demand Prediction — Source Code Table of Contents

This document provides an overview of the source code archive for the **London Bike Demand Prediction** project.  
It lists all files and directories with short descriptions to help the reader navigate the codebase.

---

## Directory and File Overview

### Root Level
 File/Folder           | Description
---------------------- | ------------------------------------------------------------
 requirements.txt      | Python dependencies required to run the project.
 predict               | Contains prediction-related scripts and the main Streamlit application.
 data                  | Raw datasets from TfL and VisualCrossing API.
 data_process          | Scripts for cleaning, merging, and preprocessing raw datasets.
 processed_data        | Outputs generated by `data_process`, used as inputs for feature engineering.
 feature_engineering   | Scripts to create predictive features from processed data.
 data_for_model        | Final datasets ready for model training and inference.
 model_training        | Scripts for training models at global, cluster, and station levels.
 models                | Saved trained model files, organised by hierarchy.
 eda                   | Exploratory Data Analysis scripts.
 eda_output            | Visualisations and results from EDA.
 figs                  | Figures used for analysis and reporting.

---

### predict
 File                  | Description
---------------------- | ------------------------------------------------------------
 app.py                | Streamlit-based web application integrating prediction logic, feature generation, and weather API retrieval.
 predict_bike_usage.py | Executes the trained model to predict bike usage.
 destination.png       | UI image resource.
 logo.jpg              | Project logo for the web interface.

---

### data_process
 File                                      | Description
------------------------------------------ | ------------------------------------------------------------
 process_step1_merge_tfl_data.py           | Merges TfL bike usage raw data into a unified dataset.
 process_step2_clean_and_aggregate.py      | Cleans merged data and aggregates by time and station.
 process_step3_weather_and_merge.py        | Merges weather data with usage data.
 process_step4_get_station_coordinates.py  | Retrieves coordinates for bike stations.
 process_step5_merge_station_coordinates.py| Merges station coordinates into the main dataset.
 process_step_cluster.py                   | Groups stations into clusters based on spatial characteristics.
 station_type.py                           | Classifies stations as weekday-oriented or leisure-oriented.
 busy_or_leisure.py                        | Labels stations by activity type based on usage patterns.
 generate_weekday_weekend_avg.py           | Computes average usage statistics for weekdays vs weekends.

---

### feature_engineering
 File                    | Description
------------------------ | ------------------------------------------------------------
 feature_engineering.py  | Generates temporal, weather, and clustering features for model input.
 step2.py                | Additional feature transformations and refinements.

---

### model_training
 File                        | Description
---------------------------- | ------------------------------------------------------------
 model_training.py           | Trains XGBoost and LightGBM models at global, cluster, and station levels.
 generate_strategy.py        | Implements automatic model selection and fallback mechanism.
 generate_hourly_station_avg.py | Produces average hourly usage per station for baseline comparison.

---

### eda
 File                    | Description
------------------------ | ------------------------------------------------------------
 eda_spatial_analysis.py | Analyses spatial distribution of bike demand.
 eda_time_analysis.py    | Examines temporal demand variations.
 eda_weather_analysis.py | Explores weather impact on bike usage.

---

## Data Sources
- **Transport for London (TfL)** — Santander Cycles trip data  
- **VisualCrossing Weather API** — Historical and forecasted weather data

---

## Notes
To run the project locally:  
1. Install dependencies from `requirements.txt`.  
2. Start the Streamlit app with:  
   ```bash
   streamlit run predict/app.py
For the full workflow (data processing → feature engineering → model training → deployment), run:

All scripts in data_process/ (in order of step number)

All scripts in feature_engineering/

All scripts in model_training/

Finally, run the Streamlit app in predict/

Live application: https://london-bike-demand-prediction.streamlit.app/
If the application is asleep due to inactivity, click Activate and wait briefly before re-entering.
Due to Streamlit deployment limitations, the online map may sometimes be blank. For full functionality, run the app locally.


